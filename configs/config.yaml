# Jotty Modular Configuration
# ============================
#
# Module-based composition (not subjective tiers)
# Choose what you need, compose your own setup
#
# Usage:
#   python run_jotty.py --config-name presets/production goal="..."
#   python run_jotty.py mas=full memory=cortex learning=td_lambda goal="..."
#
# Inspired by AIME's approach:
#   python train.py env=walker world_model=rssm

defaults:
  - mas: full                    # Multi-Agent System (minimal, full)
  - orchestrator: conductor      # Coordination (simple, conductor, universal)
  - memory: hierarchical         # Storage (simple, chroma, hierarchical, cortex)
  - learning: none               # RL algorithms (none, q_learning, td_lambda, marl)
  - validation: planner_reviewer # Quality control (none, planner_reviewer, multi_round)
  - tools: registry              # Tool mgmt (simple, registry, auto_discovery)
  - experts: none                # Domain experts (none, research, full)
  - communication: hierarchical  # Message passing (simple, hierarchical, slack)
  - _self_

# Global Settings
# ---------------

# LLM Provider
lm:
  model: gpt-4o-mini
  api_key: ${oc.env:OPENAI_API_KEY}
  temperature: 0.7
  max_tokens: 4000

# Execution
execution:
  max_steps: 30
  timeout: 300.0
  parallel: true

# Logging
logging:
  level: INFO
  format: "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
