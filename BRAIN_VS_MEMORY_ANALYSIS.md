# üß† Brain vs Memory: Implementation Analysis in Jotty

**Understanding the Two Complementary Memory Systems**

---

## üìã Executive Summary

Jotty has **TWO SEPARATE** memory systems that work together:

1. **Memory (HierarchicalMemory)** - Direct, immediate storage and retrieval
2. **Brain (BrainInspiredMemoryManager)** - Neuroscience-inspired consolidation and pattern extraction

They serve **different purposes** and operate at **different timescales**.

---

## üéØ Key Differences at a Glance

| Aspect | **Memory (HierarchicalMemory)** | **Brain (BrainInspiredMemoryManager)** |
|--------|--------------------------------|----------------------------------------|
| **Purpose** | Direct storage/retrieval for agents | Consolidation and pattern extraction |
| **When Used** | During execution (online) | During "sleep" (offline consolidation) |
| **Storage Model** | 5-level hierarchy (Episodic‚ÜíCausal) | 2-level (Hippocampus‚ÜíNeocortex) |
| **Access Pattern** | Immediate retrieval via RAG | Batch consolidation via SWR replay |
| **Update Frequency** | Every episode/action | Every N episodes (sleep interval) |
| **Learning Mechanism** | TD(Œª) value updates | Pattern extraction from replay |
| **Output** | Memories injected into prompts | Consolidated patterns injected into prompts |

---

## üß† Memory System (HierarchicalMemory)

### Purpose
**Direct, immediate memory storage and retrieval** for agents during execution.

### Architecture

```
HierarchicalMemory (cortex.py)
‚îú‚îÄ‚îÄ EPISODIC    - Raw experiences, specific events
‚îú‚îÄ‚îÄ SEMANTIC    - Abstracted patterns, generalizations  
‚îú‚îÄ‚îÄ PROCEDURAL  - How-to knowledge, step sequences
‚îú‚îÄ‚îÄ META        - Learning wisdom, when to use what
‚îî‚îÄ‚îÄ CAUSAL      - Why things work, cause-effect relationships
```

### How It Works

1. **Storage** (`store()`):
   ```python
   memory.store(
       content="Successfully used partition column",
       level=MemoryLevel.SEMANTIC,
       goal="Count P2P transactions",
       initial_value=0.8
   )
   ```

2. **Retrieval** (`retrieve()`):
   ```python
   memories = memory.retrieve(
       query="How to count transactions?",
       goal="Count P2P transactions",
       budget_tokens=1000
   )
   # Returns: List[MemoryEntry] - injected into prompts
   ```

3. **Value Updates** (TD(Œª)):
   ```python
   # After episode, TD(Œª) updates memory values
   # V(memory) = V(memory) + Œ± * (reward - V(memory))
   # High-value memories ‚Üí more likely retrieved
   ```

### Key Features

- **LLM-based RAG**: No embeddings, uses keyword pre-filter + LLM scoring
- **Goal-conditioned values**: Same memory has different values for different goals
- **Deduplication**: Prevents storing duplicate memories
- **Capacity limits**: Each level has max capacity (enforced by value-based pruning)
- **Access tracking**: Tracks which memories are accessed most (UCB exploration)

### When Used

- **During execution**: Agents store experiences immediately
- **During planning**: Agents retrieve relevant memories for context
- **After episodes**: TD(Œª) updates memory values based on outcomes

### Output Format

```python
# Consolidated knowledge injected into prompts:
consolidated = memory.get_consolidated_knowledge(
    goal="Count P2P transactions",
    max_items=10
)

# Returns:
"""
## Learned Patterns:
1. Use partition column for date filters (V=0.850)
2. Avoid transaction_category column (V=0.200)
3. For P2P queries, use partition_date >= start_date (V=0.800)
...
"""
```

---

## üß† Brain System (BrainInspiredMemoryManager)

### Purpose
**Neuroscience-inspired consolidation** that extracts patterns from experiences during "sleep" periods.

### Architecture

```
BrainInspiredMemoryManager (memory_orchestrator.py)
‚îú‚îÄ‚îÄ Hippocampus  - Short-term, high-detail episodic storage
‚îî‚îÄ‚îÄ Neocortex    - Long-term, abstracted semantic patterns
```

### How It Works

1. **Experience Storage** (`store_experience()`):
   ```python
   brain.store_experience(
       experience={
           "goal": "Count P2P transactions",
           "actor": "SQLGenerator",
           "success": True,
           "action": "Used partition column"
       },
       reward=1.0
   )
   # Stored in Hippocampus (short-term)
   ```

2. **Consolidation** (`trigger_consolidation()`):
   ```python
   # Triggered every N episodes (sleep_interval)
   if brain.should_consolidate():
       brain.trigger_consolidation()
       
   # Process:
   # 1. Select experiences for replay (high priority)
   # 2. Sharp-Wave Ripple replay (10-20x speed)
   # 3. Extract patterns (episodic ‚Üí semantic)
   # 4. Transfer to Neocortex (long-term)
   # 5. Synaptic pruning (remove weak memories)
   ```

3. **Pattern Extraction**:
   ```python
   # During consolidation:
   patterns = brain._sharp_wave_ripple_replay(experiences)
   # Extracts: "‚úÖ Strategy 'partition column' tends to succeed"
   # Transfers to Neocortex as SemanticPattern
   ```

### Key Features

- **Sharp-Wave Ripple (SWR)**: Rapid replay during consolidation (like brain during sleep)
- **Hippocampal Selection**: Prioritizes high-reward, novel, goal-relevant experiences
- **Systems Consolidation**: Transfers patterns from Hippocampus ‚Üí Neocortex
- **Synaptic Pruning**: Removes weak memories, strengthens strong ones
- **Novelty Detection**: Computes how novel each experience is

### When Used

- **During execution**: Experiences stored in Hippocampus
- **During sleep**: Consolidation triggered every N episodes
- **After consolidation**: Patterns available for retrieval

### Output Format

```python
# Consolidated knowledge from Neocortex:
knowledge = brain.get_consolidated_knowledge(
    query="How to count transactions?",
    max_items=10
)

# Returns:
"""
# Brain-Consolidated Knowledge (Neocortex):
# 200 total patterns, showing top 10

1. ‚úÖ Strategy 'partition column' tends to succeed (reward: 0.85)
   (strength: 2.30, sources: 5, consolidated: 120s ago)

2. ‚ùå Strategy 'transaction_category' tends to fail (reward: 0.20)
   (strength: 1.80, sources: 3, consolidated: 300s ago)
...
"""
```

---

## üîÑ How They Work Together

### The Complete Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EPISODE EXECUTION                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Agent executes action            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                       ‚îÇ
                ‚ñº                       ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ MEMORY (Online)  ‚îÇ    ‚îÇ BRAIN (Online)        ‚îÇ
    ‚îÇ                  ‚îÇ    ‚îÇ                       ‚îÇ
    ‚îÇ Store experience ‚îÇ    ‚îÇ Store experience      ‚îÇ
    ‚îÇ in EPISODIC      ‚îÇ    ‚îÇ in Hippocampus        ‚îÇ
    ‚îÇ                  ‚îÇ    ‚îÇ                       ‚îÇ
    ‚îÇ Value updated    ‚îÇ    ‚îÇ Priority computed     ‚îÇ
    ‚îÇ via TD(Œª)        ‚îÇ    ‚îÇ (reward, novelty)     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                       ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Episode ends                    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Check: Should consolidate?      ‚îÇ
        ‚îÇ   (episodes_since_sleep >= N)     ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                       ‚îÇ
                ‚ñº                       ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ MEMORY (Offline) ‚îÇ    ‚îÇ BRAIN (Sleep)         ‚îÇ
    ‚îÇ                  ‚îÇ    ‚îÇ                       ‚îÇ
    ‚îÇ Consolidation:   ‚îÇ    ‚îÇ Sharp-Wave Ripple:    ‚îÇ
    ‚îÇ - Move EPISODIC  ‚îÇ    ‚îÇ - Replay experiences  ‚îÇ
    ‚îÇ   ‚Üí SEMANTIC     ‚îÇ    ‚îÇ - Extract patterns    ‚îÇ
    ‚îÇ - Update values  ‚îÇ    ‚îÇ - Transfer to        ‚îÇ
    ‚îÇ - Prune low-val  ‚îÇ    ‚îÇ   Neocortex           ‚îÇ
    ‚îÇ                  ‚îÇ    ‚îÇ - Synaptic pruning    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                       ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Next Episode                     ‚îÇ
        ‚îÇ                                    ‚îÇ
        ‚îÇ   Both systems provide context:    ‚îÇ
        ‚îÇ   - Memory: Retrieved memories     ‚îÇ
        ‚îÇ   - Brain: Consolidated patterns    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Example: Complete Learning Cycle

**Episode 1:**
```python
# Agent tries approach A ‚Üí FAILS
memory.store("Avoid approach A", level=EPISODIC, value=0.2)
brain.store_experience({"action": "approach A", "success": False}, reward=0.2)

# Agent tries approach B ‚Üí SUCCEEDS
memory.store("Use approach B", level=EPISODIC, value=0.8)
brain.store_experience({"action": "approach B", "success": True}, reward=0.8)
```

**After Episode 1:**
```python
# Memory: TD(Œª) updates values
# V("Avoid approach A") = 0.2 ‚Üí 0.15 (decay)
# V("Use approach B") = 0.8 ‚Üí 0.85 (reinforcement)

# Brain: Not yet consolidated (only 1 episode)
# Hippocampus: 2 experiences stored
```

**Episode 2:**
```python
# Similar query arrives
# Memory retrieval:
memories = memory.retrieve("How to count?", goal="Count P2P")
# Returns: ["Use approach B" (V=0.85), "Avoid approach A" (V=0.15)]
# Injected into prompt ‚Üí Agent uses approach B immediately

# Brain: Still not consolidated (only 2 episodes)
```

**Episode 3:**
```python
# After episode 3, consolidation triggered (sleep_interval=3)

# Memory consolidation:
# - EPISODIC ‚Üí SEMANTIC: "Use approach B" moved to SEMANTIC level
# - Values updated further

# Brain consolidation (Sharp-Wave Ripple):
# 1. Select experiences for replay (high priority)
# 2. Replay experiences (10-20x speed)
# 3. Extract pattern: "‚úÖ Strategy 'approach B' tends to succeed"
# 4. Transfer to Neocortex
# 5. Prune weak memories
```

**Episode 4:**
```python
# Both systems provide context:

# Memory:
consolidated_memory = memory.get_consolidated_knowledge(goal="Count P2P")
# Returns: "Use approach B (V=0.90)" from SEMANTIC level

# Brain:
brain_patterns = brain.get_consolidated_knowledge(query="How to count?")
# Returns: "‚úÖ Strategy 'approach B' tends to succeed (strength: 2.5)"

# Both injected into prompt ‚Üí Agent masters the pattern!
```

---

## üìä Detailed Comparison

### 1. Storage Model

**Memory:**
- **5 levels**: Episodic ‚Üí Semantic ‚Üí Procedural ‚Üí Meta ‚Üí Causal
- **Goal-conditioned**: Same memory has different values per goal
- **Direct storage**: `store()` called immediately during execution
- **Capacity**: Per-level limits (e.g., EPISODIC=10000, SEMANTIC=5000)

**Brain:**
- **2 levels**: Hippocampus (short-term) ‚Üí Neocortex (long-term)
- **Reward-based**: Prioritizes high-reward, novel experiences
- **Buffered storage**: Experiences stored in buffer, consolidated later
- **Capacity**: Fixed limits (Hippocampus=100, Neocortex=200)

### 2. Update Frequency

**Memory:**
- **Continuous**: Updated every episode via TD(Œª)
- **Immediate**: Values updated after each action
- **Online learning**: Happens during execution

**Brain:**
- **Batch**: Consolidated every N episodes (sleep_interval)
- **Delayed**: Patterns extracted during "sleep"
- **Offline learning**: Happens during consolidation

### 3. Learning Mechanism

**Memory:**
```python
# TD(Œª) Learning:
V(memory) = V(memory) + Œ± * (reward - V(memory)) * Œª^k

# Where:
# - Œ± = learning rate
# - Œª = eligibility trace decay
# - k = steps since memory was accessed
```

**Brain:**
```python
# Pattern Extraction:
1. Select experiences for replay (priority > threshold)
2. Replay experiences (strengthen traces)
3. Extract abstract patterns
4. Transfer to Neocortex (consolidate)
5. Prune weak memories (homeostasis)
```

### 4. Retrieval Mechanism

**Memory:**
- **LLM-based RAG**: Keyword pre-filter + LLM semantic scoring
- **Goal-aware**: Retrieves memories relevant to current goal
- **Budget-aware**: Respects token budget
- **Multi-level**: Can retrieve from multiple levels simultaneously

**Brain:**
- **Pattern-based**: Returns consolidated patterns from Neocortex
- **Strength-ranked**: Sorted by pattern strength
- **Source-count**: Shows how many experiences support each pattern

### 5. What Gets Injected into Prompts

**Memory:**
```python
"""
## Learned Patterns (from Memory):
1. Use partition column for date filters (V=0.850, accessed 5 times)
2. Avoid transaction_category column (V=0.200, accessed 2 times)
3. For P2P queries, use partition_date >= start_date (V=0.800)
"""
```

**Brain:**
```python
"""
# Brain-Consolidated Knowledge (Neocortex):
1. ‚úÖ Strategy 'partition column' tends to succeed (reward: 0.85)
   (strength: 2.30, sources: 5, consolidated: 120s ago)
2. ‚ùå Strategy 'transaction_category' tends to fail (reward: 0.20)
   (strength: 1.80, sources: 3, consolidated: 300s ago)
"""
```

---

## üéØ When to Use Which

### Use Memory When:
- ‚úÖ Need **immediate** storage/retrieval during execution
- ‚úÖ Need **goal-conditioned** values (same memory, different goals)
- ‚úÖ Need **fine-grained** control over memory levels
- ‚úÖ Need **deduplication** and **capacity management**
- ‚úÖ Need **access tracking** for exploration

### Use Brain When:
- ‚úÖ Need **pattern extraction** from multiple experiences
- ‚úÖ Need **neuroscience-inspired** consolidation
- ‚úÖ Need **batch processing** of experiences
- ‚úÖ Need **abstract patterns** rather than specific memories
- ‚úÖ Need **sleep-like consolidation** cycles

### Use Both When:
- ‚úÖ **Best of both worlds**: Immediate storage + pattern extraction
- ‚úÖ **Complementary**: Memory for execution, Brain for consolidation
- ‚úÖ **Full learning**: Online updates + offline consolidation

---

## üîß Configuration

### Memory Configuration

```python
config = JottyConfig(
    # Memory capacities
    episodic_capacity=10000,
    semantic_capacity=5000,
    procedural_capacity=3000,
    meta_capacity=1000,
    causal_capacity=500,
    
    # Memory features
    enable_deduplication=True,
    enable_goal_hierarchy=True,
    
    # TD(Œª) learning
    enable_rl=True,
    td_lambda=0.7,
    learning_rate=0.1
)
```

### Brain Configuration

```python
# In Conductor initialization:
brain = BrainInspiredMemoryManager(
    sleep_interval=3,              # Consolidate every 3 episodes
    max_hippocampus_size=100,     # Max episodic memories
    max_neocortex_size=200,       # Max semantic patterns
    replay_threshold=0.7,         # Min priority for replay
    novelty_weight=0.4,           # Weight for novelty
    reward_weight=0.3,            # Weight for reward salience
    frequency_weight=0.3          # Weight for frequency
)
```

---

## üìà Performance Characteristics

### Memory
- **Storage**: O(1) per memory entry
- **Retrieval**: O(M) where M = number of memories (LLM scoring)
- **Update**: O(1) per memory (TD(Œª) update)
- **Consolidation**: O(M) per level (capacity enforcement)

### Brain
- **Storage**: O(1) per experience
- **Consolidation**: O(H log H) where H = hippocampus size
  - Selection: O(H)
  - Replay: O(S) where S = selected experiences
  - Pattern extraction: O(S)
  - Transfer: O(S log N) where N = neocortex size
- **Retrieval**: O(N) where N = neocortex size (pattern ranking)

---

## üêõ Common Issues and Solutions

### Issue 1: Memory Not Being Retrieved

**Symptom**: Agents don't use learned memories

**Solution**:
```python
# Check memory retrieval:
memories = memory.retrieve(query, goal, budget_tokens=1000)
if not memories:
    # Memory might be empty or query doesn't match
    # Check: memory.get_statistics()
```

### Issue 2: Brain Not Consolidating

**Symptom**: Patterns not being extracted

**Solution**:
```python
# Check consolidation trigger:
if brain.should_consolidate():
    brain.trigger_consolidation()
    
# Check: brain.get_statistics()
# Should show: episodes_since_sleep, total_consolidations
```

### Issue 3: Both Systems Providing Redundant Context

**Symptom**: Prompts too long with duplicate information

**Solution**:
```python
# Use one or the other, or merge intelligently:
memory_context = memory.get_consolidated_knowledge(goal, max_items=5)
brain_context = brain.get_consolidated_knowledge(query, max_items=5)

# Merge with deduplication:
combined = merge_contexts(memory_context, brain_context)
```

---

## üéì Scientific Basis

### Memory (HierarchicalMemory)
- **Aristotle**: Knowledge hierarchy (Episteme, Techne, Phronesis)
- **Shannon**: Information theory (deduplication, compression)
- **TD Learning**: Temporal difference learning (Sutton & Barto)

### Brain (BrainInspiredMemoryManager)
- **Buzs√°ki (2015)**: Sharp-wave ripple consolidation
- **Dudai et al. (2015)**: Hippocampal selection
- **McClelland et al. (1995)**: Systems consolidation
- **Tononi & Cirelli (2014)**: Synaptic homeostasis

---

## üìù Summary

### Memory = Immediate, Direct Storage
- **When**: During execution
- **What**: Specific experiences, goal-conditioned values
- **How**: TD(Œª) updates, LLM-based RAG retrieval
- **Output**: Memories injected into prompts

### Brain = Consolidation, Pattern Extraction
- **When**: During "sleep" (consolidation cycles)
- **What**: Abstract patterns, consolidated knowledge
- **How**: Sharp-Wave Ripple replay, systems consolidation
- **Output**: Patterns injected into prompts

### Together = Complete Learning System
- **Memory**: Online learning, immediate feedback
- **Brain**: Offline consolidation, pattern extraction
- **Combined**: Best of both worlds!

---

*For implementation details, see:*
- `core/memory/cortex.py` - HierarchicalMemory
- `core/memory/memory_orchestrator.py` - BrainInspiredMemoryManager
- `core/orchestration/conductor.py` - Integration
