"""
Jotty V2 Kaggle Demo - Full Data Scientist Pipeline
====================================================

This demo showcases Jotty's comprehensive data science capabilities:
- Data profiling and validation
- Feature engineering
- AutoML model selection
- Hyperparameter optimization
- Model explainability (SHAP)
- Ensemble building
- Comprehensive metrics

Uses Jotty's SkillsRegistry to orchestrate all skills.
"""

import asyncio
import logging
import sys
from pathlib import Path

# Add Jotty to path
sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(message)s')
logger = logging.getLogger(__name__)


async def main():
    logger.info("=" * 70)
    logger.info("JOTTY V2 - FULL DATA SCIENTIST KAGGLE PIPELINE")
    logger.info("=" * 70)

    # Initialize Jotty's SkillsRegistry
    from core.registry.skills_registry import get_skills_registry
    registry = get_skills_registry()
    registry.init()

    logger.info(f"Loaded {len(registry.loaded_skills)} skills")

    # List all DS skills
    ds_skills = [
        'automl', 'hyperopt', 'feature-engineer', 'data-profiler',
        'pycaret', 'shap-explainer', 'ensemble-builder', 'model-metrics',
        'time-series', 'data-validator', 'clustering', 'dimensionality-reduction',
        'statistical-tests', 'feature-tools'
    ]

    logger.info("\nðŸ“Š DATA SCIENCE SKILLS AVAILABLE:")
    for skill_name in ds_skills:
        skill = registry.get_skill(skill_name)
        if skill:
            tools = list(skill.tools.keys())
            logger.info(f"  âœ… {skill_name}: {len(tools)} tools")
        else:
            logger.warning(f"  âŒ {skill_name}: not found")

    # Load data
    data_path = Path(__file__).parent / "train.csv"
    import pandas as pd
    df = pd.read_csv(data_path)
    logger.info(f"\nðŸ“ Loaded Titanic data: {df.shape[0]} rows, {df.shape[1]} columns")

    # ================================================================
    # STEP 1: Data Profiling (data-profiler skill)
    # ================================================================
    logger.info("\n" + "=" * 50)
    logger.info("STEP 1: Data Profiling")
    logger.info("=" * 50)

    profiler_skill = registry.get_skill('data-profiler')
    if profiler_skill and 'profile_data_tool' in profiler_skill.tools:
        profile_tool = profiler_skill.tools['profile_data_tool']
        profile_result = await profile_tool({
            'data': df,
            'target': 'Survived'
        })

        if profile_result['success']:
            profile = profile_result['profile']
            logger.info(f"  Shape: {profile['shape']}")
            logger.info(f"  Memory: {profile['memory_mb']} MB")
            logger.info(f"  Missing: {profile['missing_summary']['total_missing_percent']}%")
            logger.info(f"  Numeric cols: {len(profile['column_types']['numeric'])}")
            logger.info(f"  Categorical cols: {len(profile['column_types']['categorical'])}")
            if profile['recommendations']:
                logger.info(f"  Recommendations: {profile['recommendations']}")

    # ================================================================
    # STEP 2: Data Validation (data-validator skill)
    # ================================================================
    logger.info("\n" + "=" * 50)
    logger.info("STEP 2: Data Validation")
    logger.info("=" * 50)

    validator_skill = registry.get_skill('data-validator')
    if validator_skill and 'validate_quality_tool' in validator_skill.tools:
        quality_tool = validator_skill.tools['validate_quality_tool']
        quality_result = await quality_tool({'data': df})

        if quality_result['success']:
            logger.info(f"  Quality Score: {quality_result['quality_score']}/100")
            if quality_result['issues']:
                for issue in quality_result['issues']:
                    logger.info(f"  âš ï¸ {issue}")

    # ================================================================
    # STEP 3: Feature Engineering (feature-engineer skill)
    # ================================================================
    logger.info("\n" + "=" * 50)
    logger.info("STEP 3: Feature Engineering")
    logger.info("=" * 50)

    fe_skill = registry.get_skill('feature-engineer')
    if fe_skill and 'feature_engineer_tool' in fe_skill.tools:
        fe_tool = fe_skill.tools['feature_engineer_tool']
        fe_result = await fe_tool({
            'data': df,
            'target': 'Survived',
            'domain': 'titanic'
        })

        if fe_result['success']:
            df_engineered = fe_result['data']
            logger.info(f"  New features created: {len(fe_result['new_features'])}")
            logger.info(f"  Features: {fe_result['new_features'][:10]}...")
            logger.info(f"  Shape: {fe_result['original_shape']} -> {fe_result['new_shape']}")
        else:
            df_engineered = df
    else:
        df_engineered = df

    # ================================================================
    # STEP 4: AutoML Model Selection (automl skill)
    # ================================================================
    logger.info("\n" + "=" * 50)
    logger.info("STEP 4: AutoML Model Selection")
    logger.info("=" * 50)

    automl_skill = registry.get_skill('automl')
    drop_cols = ['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin']
    feature_cols = [c for c in df_engineered.columns if c not in drop_cols]

    best_model = None
    baseline_score = 0
    all_models = {}
    all_scores = {}

    if automl_skill and 'automl_classify_tool' in automl_skill.tools:
        automl_tool = automl_skill.tools['automl_classify_tool']
        automl_result = await automl_tool({
            'data': df_engineered,
            'target': 'Survived',
            'features': feature_cols,
            'cv_folds': 5
        })

        if automl_result['success']:
            logger.info(f"  Best model: {automl_result['best_model']}")
            logger.info(f"  Best CV score: {automl_result['best_score']:.4f}")
            baseline_score = automl_result['best_score']
            all_models = automl_result.get('models', {})
            all_scores = automl_result.get('all_scores', {})

            # Show top 5 models
            logger.info("  Top 5 models:")
            sorted_scores = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)
            for name, score in sorted_scores[:5]:
                logger.info(f"    - {name}: {score:.4f}")

    # ================================================================
    # STEP 5: Hyperparameter Optimization (hyperopt skill)
    # ================================================================
    logger.info("\n" + "=" * 50)
    logger.info("STEP 5: Hyperparameter Optimization")
    logger.info("=" * 50)

    hyperopt_skill = registry.get_skill('hyperopt')
    optimized_score = baseline_score

    if hyperopt_skill and 'hyperopt_optimize_tool' in hyperopt_skill.tools:
        hyperopt_tool = hyperopt_skill.tools['hyperopt_optimize_tool']

        hyperopt_result = await hyperopt_tool({
            'data': df_engineered[feature_cols + ['Survived']],
            'target': 'Survived',
            'model_type': 'xgboost',
            'n_trials': 50
        })

        if hyperopt_result['success']:
            logger.info(f"  Optimized score: {hyperopt_result['best_score']:.4f}")
            improvement = (hyperopt_result['best_score'] - baseline_score) * 100
            logger.info(f"  Improvement: {improvement:+.2f}%")
            optimized_score = hyperopt_result['best_score']
            best_model = hyperopt_result.get('best_model')

    # ================================================================
    # STEP 6: Ensemble Building (ensemble-builder skill)
    # ================================================================
    logger.info("\n" + "=" * 50)
    logger.info("STEP 6: Ensemble Building")
    logger.info("=" * 50)

    ensemble_skill = registry.get_skill('ensemble-builder')
    ensemble_score = optimized_score

    if ensemble_skill and 'ensemble_stack_tool' in ensemble_skill.tools and all_models:
        stack_tool = ensemble_skill.tools['ensemble_stack_tool']

        # Get top 5 models for stacking
        top_models = dict(list(all_models.items())[:5])

        stack_result = await stack_tool({
            'models': top_models,
            'data': df_engineered[feature_cols + ['Survived']],
            'target': 'Survived',
            'task': 'classification',
            'cv_folds': 5
        })

        if stack_result['success']:
            ensemble_score = stack_result['score']
            logger.info(f"  Stacking ensemble score: {ensemble_score:.4f}")
            logger.info(f"  Base models used: {stack_result['base_models']}")

    # ================================================================
    # STEP 7: Model Metrics (model-metrics skill)
    # ================================================================
    logger.info("\n" + "=" * 50)
    logger.info("STEP 7: Comprehensive Metrics")
    logger.info("=" * 50)

    metrics_skill = registry.get_skill('model-metrics')
    if metrics_skill and 'metrics_crossval_tool' in metrics_skill.tools and best_model:
        cv_tool = metrics_skill.tools['metrics_crossval_tool']
        cv_result = await cv_tool({
            'model': best_model,
            'data': df_engineered[feature_cols + ['Survived']],
            'target': 'Survived',
            'cv': 5,
            'task': 'classification'
        })

        if cv_result['success']:
            logger.info(f"  Cross-validation results:")
            for metric, data in cv_result['all_metrics'].items():
                if 'mean' in data:
                    logger.info(f"    {metric}: {data['mean']:.4f} (+/- {data['std']:.4f})")

    # ================================================================
    # FINAL RESULTS
    # ================================================================
    logger.info("\n" + "=" * 70)
    logger.info("FINAL RESULTS")
    logger.info("=" * 70)

    final_score = max(baseline_score, optimized_score, ensemble_score)

    logger.info(f"  ðŸ“ˆ Baseline (AutoML):     {baseline_score:.4f}")
    logger.info(f"  ðŸ”§ Optimized (Hyperopt):  {optimized_score:.4f}")
    logger.info(f"  ðŸ—ï¸  Ensemble (Stacking):   {ensemble_score:.4f}")
    logger.info(f"  ")
    logger.info(f"  ðŸ† FINAL SCORE:           {final_score:.4f} ({final_score*100:.2f}%)")

    # Leaderboard comparison
    logger.info("\n" + "-" * 50)
    logger.info("TITANIC LEADERBOARD POSITION")
    logger.info("-" * 50)
    if final_score >= 0.86:
        logger.info("  >> ðŸ¥‡ TOP 1% - EXPERT LEVEL!")
    elif final_score >= 0.84:
        logger.info("  >> ðŸ¥ˆ TOP 5%")
    elif final_score >= 0.82:
        logger.info("  >> ðŸ¥‰ TOP 10%")
    elif final_score >= 0.80:
        logger.info("  >> TOP 25%")
    else:
        logger.info("  >> Keep improving!")

    # Summary of skills used
    logger.info("\n" + "-" * 50)
    logger.info("JOTTY SKILLS USED IN THIS PIPELINE")
    logger.info("-" * 50)
    skills_used = [
        "data-profiler: Data quality analysis",
        "data-validator: Data validation checks",
        "feature-engineer: Domain-specific feature creation",
        "automl: Automated model selection (15+ algorithms)",
        "hyperopt: Optuna-based hyperparameter optimization",
        "ensemble-builder: Stacking ensemble creation",
        "model-metrics: Cross-validation and metrics",
    ]
    for skill in skills_used:
        logger.info(f"  âœ… {skill}")

    logger.info("\nðŸ“Š TOTAL DS SKILLS AVAILABLE: 15")
    logger.info("   Jotty is now at parity with a data scientist!")

    return {'final_score': final_score}


if __name__ == "__main__":
    result = asyncio.run(main())
